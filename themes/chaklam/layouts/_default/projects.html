{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      <h3>Culture & Research Philosophy</h3>
      <p>Our interdisciplinary team works at the frontier of <strong>natural language processing</strong> and <strong>human-computer interaction</strong> and its intersection, guided by curiosity and scientific rigor:</p>
      <ul>
        <li><strong>Experimental</strong>: Conduct reproducible experiments that advance fundamental understanding.</li>
        <li><strong>Computational</strong>: Leverage algorithms, models, and coding expertise to tackle challenging questions.</li>
      </ul>

      <h3>Lab Entry</h3>
      <p>We welcome students from all disciplines with strong curiosity and a passion for rigorous, original research.</p>

      <h3>Research Topics</h3>

      <ol class="project-list">

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 1: Liveness Detection</strong>
      <p>
        Researching biometric security by studying biases, creating datasets, 
        and building smaller, better models to defend against fraud, 
        spoof attacks, and morphing.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 2: Facial Recognition</strong>
      <p>
        Focusing on responsible and secure facial recognition by studying biases, 
        creating datasets, defining best practices, and training models 
        to resist attacks.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 3: OCR (Optical Character Recognition)</strong>
      <p>
        Advancing OCR technology by studying best practices, optimizing 
        pipelines, creating robust datasets, and training improved models.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 4: Agentic AI</strong>
      <p>
        Studying best practices for multi-agent frameworks and their 
        application in creating AI chatbots, AI tutors, and AI interviewers.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 5: Synthetic Personas</strong>
      <p>
        Exploring the use of AI-driven synthetic personas as a 
        replacement or augmentation for traditional market research methods.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 6: Medical VQA</strong>
      <p>
        Advancing Medical Visual Question Answering by designing 
        better neural architectures and creating richer, high-quality datasets.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 7: Human-AI Interaction</strong>
      <p>
        Focusing on how AI systems can be designed to directly 
        augment and enhance human abilities like cognition, creativity, and learning.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 8: Speech2Text and Voice Cloning</strong>
      <p>
        Advancing speech technologies by creating new datasets and 
        training improved models for robust transcription and high-fidelity voice cloning.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 9: EEG</strong>
      <p>
        Developing novel Brain-Computer Interfaces (BCI), with a focus on 
        hybrid spellers that utilize both SSVEP and P300 signals.
      </p>
    </div>
  </li>

  <li class="project-item">
    <div class="project-text">
      <strong>Topic 10: Raman Spectroscopy</strong>
      <p>
        Applying Raman and infrared spectroscopy to develop practical, 
        non-invasive medical devices, such as a portable glucose meter.
      </p>
    </div>
  </li>

</ol>

      {{/*  <ol class="project-list">

        <!-- Topic 1: Human–AI Interaction -->
        <li class="project-item">
          <img src="/img/demo2/human.jpg" alt="Human–AI Interaction" class="project-img">
          <div class="project-text">
            <strong>Topic 1: Human–AI Interaction</strong>
            <p>
              We study how AI can be designed to augment rather than replace human abilities. 
              Our focus is on enhancing cognition, creativity, and decision-making while 
              supporting well-being and fairness. We also explore the design of AI-enabled 
              applications such as tutors, interviewers, and mental health companions, with 
              attention to human growth and well-being.
            </p>
            <ul>
              <li>How can AI enhance <b>human cognition</b>, creativity, decision-making, and well-being while reducing biases?</li>
              <li>What AI-enabled <b>applications</b> (e.g., AI tutors, AI interviewers, mental health chatbots, medical VQA) best support human growth and well-being?</li>
              <li>What design <b>principles</b> and psychological theories ensure these systems are effective?</li>
            </ul>
          </div>
        </li>

        <!-- Topic 2: Natural Language Processing -->
        <li class="project-item">
          <img src="/img/demo2/slm.jpg" alt="Natural Language Processing" class="project-img">
          <div class="project-text">
            <strong>Topic 2: Natural Language Processing</strong>
            <p>
              Our NLP research explores how to make language and speech technologies more 
              efficient, accessible, and powerful. We investigate training frameworks for 
              compact small language models that retain much of the capability of large 
              models, while also advancing speech recognition, diarization, and mixed-language 
              processing to perform robustly in real-world environments.   We are also interested to combine 
              computer science techniques like ontology or first-order logic to improve reasoning capabilities of small language models.
            </p>
            <ul>
              <li>How can we create a framework for training <b>small language models</b> that achieve LLM-like power in targeted domains?</li>
              <li>What methods enable compact models to generalize across tasks with limited data?</li>
              <li>Can we combine <b>ontology</b> or first-order logic to improve the reasoning capabilities of small language models?</li>
              <li>How do we advance <b>speech recognition</b>, diarization, voice cloning and mixed-language processing for real-world environments?</li>
            </ul>
          </div>
        </li>

        <!-- Topic 3: Neural Architectures & Multimodal Models -->
        <li class="project-item">
          <img src="/img/demo2/model.png" alt="Multimodal Models" class="project-img">
          <div class="project-text">
            <strong>Topic 3: Neural Architectures & Multimodal Models</strong>
            <p>
              Beyond applications, we focus on the foundations of building better models. This includes analyzing neural architectures, adding novel components for improved reasoning, and developing multimodal systems that integrate vision, language, and domain knowledge. We are especially interested in high-impact areas such as medical visual question answering (VQA).
            </p>
            <ul>
              <li>What <b>architectural innovations</b> improve reasoning and generalization in neural networks?</li>
              <li>How can we design <b>multimodal models</b> that effectively combine text, speech, and vision?</li>
              <li>How can we combine <b>graph</b>, <b>attention</b>, or <b>sequential</b> components for better performance?</li>
            </ul>
          </div>
        </li>

      </ol>  */}}


    </div>
  </section><!-- End Portfolio Details Section -->
</main>

<style>
  .project-list {
    list-style: none;
    padding: 0;
  }
  .project-item {
    display: flex;
    align-items: flex-start;
    margin-bottom: 30px;
  }
  .project-img {
    width: 140px;
    height: auto;
    margin-right: 20px;
    border-radius: 8px;
    object-fit: cover;
  }
  .project-text {
    flex: 1;
  }
  .project-text ul {
    padding-left: 20px;
  }
  @media (max-width: 768px) {
    .project-item {
      flex-direction: column;
      align-items: center;
      text-align: center;
    }
    .project-img {
      margin-right: 0;
      margin-bottom: 10px;
    }
  }
</style>

{{ end }}
