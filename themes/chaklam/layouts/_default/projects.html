{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      <h3>Culture & Research Philosophy</h3>
      <p>Our interdisciplinary team operates at the intersection of <strong>natural language processing</strong> and <strong>human-computer interaction</strong>. We emphasize:</p>
      <ul>
        <li><strong>Experimental</strong>: Conduct rigorous, reproducible experiments to advance scientific knowledge.</li>
        <li><strong>Computational</strong>: Apply algorithms, mathematical models, and coding expertise to solve challenging problems.</li>
      </ul>

      <h3>Lab Entry</h3>
      <p>We welcome students from all disciplines, particularly those with strong curiosity and a passion for research and innovation.</p>

      <h3>Research Tracks</h3>
      <p>Our lab focuses on frontier problems in AI and HCI, aiming for high-impact publications and novel contributions.</p>

      <ol class="project-list">

        <!-- Track 1: Small Language Models -->
        <li class="project-item">
          <img src="/img/demo2/slm.jpg" alt="Small Language Models" class="project-img">
          <div class="project-text">
            <strong>Track 1: Small Language Models (SLM)</strong>
            <p>Exploring compression, efficient tokenization, low-resource adaptation, and robustness evaluation to make LLMs more efficient and generalizable.</p>
          </div>
        </li>

        <!-- Track 2: Multilingual Speech Recognition -->
        <li class="project-item">
          <img src="/img/demo2/avatar.jpg" alt="Multilingual Speech Recognition" class="project-img">
          <div class="project-text">
            <strong>Track 2: Multilingual & Mixed-Language Speech Recognition</strong>
            <p>Studying cross-lingual transfer, code-switching, low-resource languages, speaker diarization, and noise-robust models for more natural human-machine speech interaction.</p>
          </div>
        </li>

        <!-- Track 3: Voice Cloning & Talking Avatars -->
        <li class="project-item">
          <img src="/img/demo2/multimodal.jpg" alt="Voice Cloning & Avatars" class="project-img">
          <div class="project-text">
            <strong>Track 3: Voice Cloning & Talking Avatars</strong>
            <p>Investigating few-shot voice synthesis, neural vocoders, lip-sync for talking avatars, and perceptual evaluation of realism and speaker identity.</p>
          </div>
        </li>

        <!-- Track 4: Human-Centered LLMs -->
        <li class="project-item">
          <img src="/img/demo2/human.jpg" alt="LLM Human Understanding" class="project-img">
          <div class="project-text">
            <strong>Track 4: LLMs that Truly Understand Humans</strong>
            <p>Developing emotionally intelligent, culturally aware, and bias-sensitive LLMs capable of understanding beliefs, behaviors, and human cognition.</p>
          </div>
        </li>

      </ol>
    </div>
  </section><!-- End Portfolio Details Section -->
</main>

<style>
  .project-list {
    list-style: none;
    padding: 0;
  }
  .project-item {
    display: flex;
    align-items: flex-start;
    margin-bottom: 30px;
  }
  .project-img {
    width: 140px;
    height: auto;
    margin-right: 20px;
    border-radius: 8px;
    object-fit: cover;
  }
  .project-text {
    flex: 1;
  }
  @media (max-width: 768px) {
    .project-item {
      flex-direction: column;
      align-items: center;
      text-align: center;
    }
    .project-img {
      margin-right: 0;
      margin-bottom: 10px;
    }
  }
</style>

{{ end }}
