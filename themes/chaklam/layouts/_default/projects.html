{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>

    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      {{/*  <p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen="" data-align="left" frameborder="0" height="315"
          src="https://www.youtube.com/embed/fMaOqt8tdsg?si=RIPSwUZCM2pqOYw6" style="margin-right:30px;"
          title="YouTube video player" width="500"></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/2e37nmzC6Ig?si=DOcD4HXIalorkoNK" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/DXnu3WY3znc?si=HWOKOSnhvaP1jAiZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <iframe width="500" height="315" src="https://www.youtube.com/embed/eK-lxMjvbVU?si=jjQM4k9uuF6kY1Wz" title="YouTube video player" frameborder="0" style="margin-left:30px;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </p>
      <!-- <h3><img alt="fun" data-align="left" data-entity-type="file" data-entity-uuid="2205d992-6a3c-48cc-8185-be3c417db181" height="311" src="/sites/default/files/inline-images/IMG20200917192032.jpg" style="margin-right: 20px;" width="500" /></h3> -->  */}}

      <h3>Culture</h3>

      <p>We strive to build an interdisciplinary team working in the area of <strong>understanding humans</strong> and <strong>improving overall human's wellbeing</strong>.  I called my area of research <b>Human AI Interaction</b>.  It's an interdisciplinary area intersecting technology and humans. Our core values are:</p>

      <ul>
        <li><strong>Experimental</strong>: We value scientific rigor, focusing on researching under strong scientific
          grounds and conducting sound experiments that provide definitive and repeatable findings.
        </li>
        <li><strong>Computational</strong>: Our scientific nature is to use algorithms, mathematical models, strong
          theoretical background, and strong coding skills.</li>
      </ul>

      <h3>Lab Entry</h3>

      <p>We welcomed students from all disciplines but those with a huge passion for research.</p>

      <h3>Problems we are interested</h3>

      <p>We are mostly interested in problems in the intersection of deep learning, human psychology, and health and well-being.</p>

      <p>Deep learning</p>
      <ol>
        <li><strong>Hybrid Transformer-SSM Architectures</strong>: How to optimally combine attention with state space components? Can we develop attention-like mechanisms within the SSM framework?What hybrid designs offer best compute/performance tradeoffs?</li>
        <li><strong>Long-Context Modeling Breakthroughs</strong>: How to effectively model 1M+ token contexts? What architectural innovations enable true long-range reasoning? How to evaluate true long-context understanding beyond retrieval?</li>
        <li><strong> Computationally-Aware Scaling Laws</strong>: This direction investigates how different architectures scale with computational resources, and what architectural decisions yield optimal scaling properties.</li>
      </ol>

      {{/*  <p style="line-height:1.38; margin-top:16px; margin-bottom:16px"><strong>Fundamental Research (suitable for Ph.D. students or Master students who want to go Ph.D.)</strong></p>  */}}
      <p>Modeling humans</p>
      <ol>
        <li><strong>Modeling humans through EEG and physiological signals</strong>: How does EEG and physiological profile looks like when humans are stressed?  engaged?  mindful? etc.  Then can we create an intervention system to improve these properties?</li>
        <li><strong>Modeling humans through language, agents and games</strong>: How can we model beliefs, emotion, cognition, behaviors, culture, and biases, etc. through language, agents, and games? </li>
        <li><strong>Understanding humans through voice and face</strong>: Can we detect depression, confidence, humours, or risk profiles from a person's voice?  What should we ask him/her to speak to detect that?  How long should that voice be?  Does it work for only certain languages? Does it get better results if we combine with facial features?</li>
      </ol>

      <p>Health and wellness</p>
      <ol>
        <li><strong>Medical Imaging</strong>: How to incorporate AI to the current workflow? What data interoperability challenges we need to concern? How to build explaninability and trust? How reasoning can be done?  Can we incorporate VQA?  How does traditional computer vision techniques compared with modern techniques like semi-supervised or self-supervised learning?  How to deal with millions of unlabeled data?  Can we use diffusion or generative AI to create infinite medical images?</li>
        <li><strong>Raman Spectroscopy</strong>: How to measure blood glucose non-invasively using Raman spectroscopy?  Can we put them into a portable low-cost machine and deploy them into households?</li>
        <li><strong>EEG BCI Speller</strong>: How to develop an effective and user-friendly BCI speller for locked-in patients using EEG?</li>
        <li><strong>Chatbot for emotional support</strong>: Can we incorporate CBT/DBT/ACT to chatbot to provide emotional support or assessments to people suffering from stress or depression?</li>
      </ol>

      <p>Internships / Applications</p>
      <ol>
        {{/*  <li><strong>Mobile Speech2Text app</strong>:  A mobile-based speech2text for tourism / policy / insurance industry</li>  */}}
        <li><strong>Avatar + Text2Speech </strong>:  Thailand still do not have its own technology in terms of voice cloning or avatar generation or text2speech, which will be useful in the domain of education and tourism. </li>
        <li><strong>Car Damage Prediction</strong>:  Current car damage prediction still suffers from low accuracy, mostly from outliers not existing in the dataset. </li>
        <li><strong>One Report Generation</strong>:  Using agentic AI to generate whole One report.</li>
        <li><strong>OCR</strong>:  Develop advanced OCR solution that accomodates dynamic forms and handwritings.</li>
        <li><strong>AI Tutor</strong>:  Using avatar technology + agentic AI to reimagine how a AI tutor should look like.</li>
        <li><strong>AI Interviewer</strong>:  Using voice + face + LLM + resume analysis to evaluate and screen candidates.</li>
        {{/*  <li><strong>Template Matching</strong>:  Develop computer vision suite of models to support manufacturing companies.</li>  */}}
      </ol>
    </div>
  </section><!-- End Portfolio Details Section -->
</main>
{{ end }}